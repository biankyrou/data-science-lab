{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas de avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Acurácia - para problemas de classificação\n",
    "- Quantas das classificações produzidas pelo modelo estão corretas dividindo pelo total de classificações realizadas.\n",
    "- Valor em [0,1] que indica a porcentagem correta. 0-100%\n",
    "-> Basicamente vou prever se, por exemplo, uma pessoa sobreviveu, ou se uma pessoa morreu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error (Erro quadrático médio) - para problemas de regressão\n",
    "- A média do quadrado das diferenças entre o valor produzido pelo modelo e o valor esperado.\n",
    "- Valor em [0,+∞] que depende da escala dos targets.\n",
    "Quanto eu devia ter previsto - quanto eu previ, elevado ao quadrado.\n",
    "→ Quanto eu devia ter previsto - quanto eu previ, elevado ao quadrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Existem muitas outras métricas: \n",
    "- Precision, Recall, AUC, F-Score, Mean Absolute Error…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Próxima seção](https://img.shields.io/badge/-%E2%9E%A1_Próxima_Seção:_Underfitting_e_Overfitting-blue?style=for-the-badge&color=007BFF)](https://github.com/biankyrou/data-science-lab/blob/main/Guia%20de%20Estudos/5-%20Machine%20Learning/4-%20Underfitting%20e%20Overfitting.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
